<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on Cinderblook's Website</title><link>https://cinderblook.github.io/posts/</link><description>Recent content in Posts on Cinderblook's Website</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>&lt;a href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank" rel="noopener">CC BY-NC 4.0&lt;/a></copyright><atom:link href="https://cinderblook.github.io/posts/index.xml" rel="self" type="application/rss+xml"/><item><title>K3S - Highly-Available-Rancher</title><link>https://cinderblook.github.io/posts/1/01/k3s-highly-available-rancher/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cinderblook.github.io/posts/1/01/k3s-highly-available-rancher/</guid><description>Overview Getting started with K3S: The primary goal here is to setup a functional highly available K3S cluster. This will include 4 necessary steps:
Setup NGINX Loadbalancer Docker Setup MySQL Docker Setup Highly Available K3s Cluster (Optional) Setup management from dev machine (Controller) Setup Rancher as a container within the cluster Prerequisites Have a dedicated Docker host virtual machine, preferrably linux Have 5 Linux virtual machines ready Two will be Master Nodes, and Three will be worker nodes.</description><content type="html"><![CDATA[<h1 id="overview">Overview</h1>
<p>Getting started with K3S: <!-- raw HTML omitted -->
The primary goal here is to setup a functional highly available K3S cluster. This will include 4 necessary steps:</p>
<ol>
<li>Setup NGINX Loadbalancer Docker</li>
<li>Setup MySQL Docker</li>
<li>Setup Highly Available K3s Cluster</li>
<li>(Optional) Setup management from dev machine (Controller)</li>
<li>Setup Rancher as a container within the cluster</li>
</ol>
<h1 id="prerequisites">Prerequisites</h1>
<ul>
<li>Have a dedicated Docker host virtual machine, preferrably linux</li>
<li>Have 5 Linux virtual machines ready
<ul>
<li>Two will be Master Nodes, and Three will be worker nodes. Each will have a dedicated IP address.</li>
</ul>
</li>
</ul>
<p>I personally ran all of my linux Virtual Machines as Ubuntu Server 20.04</p>
<h1 id="1-setup-nginx-loadbalancer-docker">1. Setup NGINX Loadbalancer Docker</h1>
<p>Log into your dedicated docker linux host and create a NGINX Loadbalancer using docker <!-- raw HTML omitted -->
Ensure docker-compose is installed</p>
<ul>
<li><code>sudo curl -L &quot;https://github.com/docker/compose/releases/download/1.29.2/docker-compose-$(uname -s)-$(uname -m)&quot; -o /usr/local/bin/docker-compose</code></li>
<li><code>sudo chmod +x /usr/local/bin/docker-compose</code></li>
</ul>
<p>After setup, create a directory for nginx, and create a file called docker-compose.yml with the following contents</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yml" data-lang="yml"><span style="display:flex;"><span><span style="color:#f92672">version</span>: <span style="color:#e6db74">&#39;3&#39;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">services</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">nginx</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">image</span>: <span style="color:#ae81ff">nginx:latest</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">container_name</span>: <span style="color:#ae81ff">nginx</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">volumes</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#ae81ff">./nginx.conf:/etc/nginx/nginx.conf</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">ports</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#ae81ff">80</span>:<span style="color:#ae81ff">80</span>
</span></span><span style="display:flex;"><span>      - <span style="color:#ae81ff">443</span>:<span style="color:#ae81ff">443</span>
</span></span><span style="display:flex;"><span>      - <span style="color:#ae81ff">6443</span>:<span style="color:#ae81ff">6443</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">restart</span>: <span style="color:#66d9ef">on</span>-<span style="color:#ae81ff">failure</span>
</span></span></code></pre></div><ul>
<li>In the same directorty, create a nginx.conf file with the following contet:
<ul>
<li><em>change &lt;IP_MASTER_NODE1 &amp; 2&gt; to your two node IP addresses. Change &lt;IP_NODE_1,2,3&gt; to Worker Node IPs</em></li>
</ul>
</li>
</ul>
<pre tabindex="0"><code class="language-conf" data-lang="conf">events{}
 
 stream {
     upstream k3s_servers {
         server &lt;IP_MASTER_NODE_1&gt;:6443;
         server &lt;IP_MASTER_NODE_2&gt;:6443;
     }
 
     server {
         listen 6443;
         proxy_pass k3s_servers;
     }
     upstream rancher_servers_http {
 	    least_conn;
 	    server &lt;IP_NODE_1&gt;:80 max_fails=3 fail_timeout=5s;
 	    server &lt;IP_NODE_2&gt;:80 max_fails=3 fail_timeout=5s;
 	    server &lt;IP_NODE_3&gt;:80 max_fails=3 fail_timeout=5s;
 	}
 	server {
 	    listen 80;
 	    proxy_pass rancher_servers_http;
 	}
 	
 	upstream rancher_servers_https {
 	    least_conn;
 	    server &lt;IP_NODE_1&gt;:443 max_fails=3 fail_timeout=5s;
 	    server &lt;IP_NODE_2&gt;:443 max_fails=3 fail_timeout=5s;
 	    server &lt;IP_NODE_3&gt;:443 max_fails=3 fail_timeout=5s;
 	}
 	server {
 	    listen     443;
 	    proxy_pass rancher_servers_https;
 	}
}
</code></pre><ul>
<li>Commands to setup:
<ul>
<li>Change nginx.conf file to match your configuration</li>
<li>Enter file directory of nginx and apply <code>sudo docker-compose up -d</code></li>
</ul>
</li>
</ul>
<h1 id="2-setup-mysql-docker">2. Setup MySQL Docker</h1>
<p>On the same dedicated docker host that the nginx loadbalancer is running on:
Create new directory for mysql and put a docker-compose.yml file in it with the following:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">version</span>: <span style="color:#e6db74">&#39;3.1&#39;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">services</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">mysql</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">image</span>: <span style="color:#ae81ff">mysql:latest</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">restart</span>: <span style="color:#ae81ff">always</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">container_name</span>: <span style="color:#ae81ff">mysql</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">ports</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#ae81ff">3306</span>:<span style="color:#ae81ff">3306</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">expose</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#e6db74">&#34;3306&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">volumes</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#ae81ff">./mysql-data:/var/lib/mysql/</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">environment</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#ae81ff">MYSQL_ROOT_PASSWORD=enter-your-password</span>
</span></span></code></pre></div><p>Commands to setup:</p>
<ul>
<li>Enter file directory of mysql and apply <code>sudo docker-compose up -d</code></li>
<li>Enter the docker to execute commands
<ul>
<li><code>sudo docker exec -it mysql bash</code></li>
</ul>
</li>
<li><code>mysql -p</code>  <em>(Enter password)</em></li>
<li>Next, create the database and assign a user to it to be used with the K3s cluster within the mysql bash shell using the following SQL commands.
<ul>
<li><em>Change &lsquo;password&rsquo; and &lsquo;user&rsquo; to your desired variables</em></li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sql" data-lang="sql"><span style="display:flex;"><span><span style="color:#66d9ef">CREATE</span> <span style="color:#66d9ef">DATABASE</span> k3s <span style="color:#66d9ef">COLLATE</span> latin1_swedish_ci;
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">CREATE</span> <span style="color:#66d9ef">USER</span> <span style="color:#960050;background-color:#1e0010">‘</span><span style="color:#66d9ef">user</span><span style="color:#960050;background-color:#1e0010">’</span><span style="color:#f92672">@</span><span style="color:#960050;background-color:#1e0010">’</span><span style="color:#f92672">%</span><span style="color:#960050;background-color:#1e0010">’</span> IDENTIFIED <span style="color:#66d9ef">BY</span> <span style="color:#960050;background-color:#1e0010">‘</span>password<span style="color:#960050;background-color:#1e0010">’</span>;
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">GRANT</span> <span style="color:#66d9ef">ALL</span> <span style="color:#66d9ef">ON</span> k3s.<span style="color:#f92672">*</span> <span style="color:#66d9ef">TO</span> <span style="color:#e6db74">&#39;user&#39;</span><span style="color:#f92672">@</span><span style="color:#e6db74">&#39;%&#39;</span>;
</span></span><span style="display:flex;"><span>FLUSH <span style="color:#66d9ef">PRIVILEGES</span>;
</span></span></code></pre></div></li>
</ul>
<p>To Note: the Database <em>MUST</em> be <em>latin1_swedish_ci</em></p>
<h1 id="3-setup-highly-available-k3s-cluster">3. Setup Highly Available K3s Cluster</h1>
<p>These will be setup in three steps. The first, setting up the first master node in the K3s cluster. Then, joining an additional master node. Finally, adding the worker nodes.</p>
<h2 id="1-primary-master-node-setup">1. Primary Master Node setup</h2>
<p>On the first Server node run these commands:</p>
<ul>
<li><code>export K3S_DATASTORE_ENDPOINT='mysql://user:password@tcp(sqlhost:3306)/database-name</code>
<ul>
<li><em>Change values to your database values. &lsquo;user&rsquo;, &lsquo;password&rsquo;, &lsquo;sqlhost&rsquo;, &lsquo;database-name&rsquo;</em></li>
</ul>
</li>
<li><code>curl -sfL https://get.k3s.io | sh -s - server --node-taint CriticalAddonsOnly=true:NoExecute --tls-san 'Load-Balancer-Address'</code></li>
</ul>
<p>After it has connected and you can successfully, check and ensure you can see the node with <code>sudo kubectl get nodes</code></p>
<ul>
<li>Obtain node-token from <code>sudo cat /var/lib/rancher/k3s/server/node-token</code>
<ul>
<li><em>This will be used in the next steps to join the second master node and the workers</em></li>
</ul>
</li>
</ul>
<h2 id="2-secondary-master-node-setup">2. Secondary Master Node setup</h2>
<p>On additional server nodes:</p>
<ul>
<li><code>export K3S_DATASTORE_ENDPOINT='mysql://user:password@tcp(sqlhost:3306)/database-name</code>
<ul>
<li><em>Change values to your database values. &lsquo;user&rsquo;, &lsquo;password&rsquo;, &lsquo;sqlhost&rsquo;, &lsquo;database-name&rsquo;</em></li>
</ul>
</li>
<li><code>Curl -sfL https://get.k3s.io | sh -s - server --node-taint CriticalAddonsOnly=true:NoExecute --tls-san 'Load-Balancer-Address' --token server-token-here sh -</code>
<ul>
<li><em>Change values to your database values. &lsquo;Load-Balancer-Address&rsquo;, &lsquo;server-token-here&rsquo;</em></li>
</ul>
</li>
</ul>
<h2 id="3-worker-node-setup">3. Worker Node Setup</h2>
<p>On all client agents to be added to cluster</p>
<ul>
<li><code>export K3S_DATASTORE_ENDPOINT='mysql://user:password@tcp(sqlhost:3306)/database-name'</code>
<ul>
<li><em>Change values to your database values. &lsquo;user&rsquo;, &lsquo;password&rsquo;, &lsquo;sqlhost&rsquo;, &lsquo;database-name&rsquo;</em></li>
</ul>
</li>
<li><code>curl -sfL https://get.k3s.io | K3S_URL=https://'Load-Balance-Address':6443 K3S_TOKEN=server-token-here sh -</code>
<ul>
<li><em>Change values to your database values. &lsquo;Load-Balancer-Address&rsquo;, &lsquo;K3S_TOKEN=server-token-here&rsquo;</em></li>
</ul>
</li>
</ul>
<h1 id="4-optional-setup-management-from-dev-machine-controller">4. (Optional) Setup management from dev machine (Controller)</h1>
<p>Once Cluster has been setup</p>
<ul>
<li>install k3s on controller machine w/ <code>curl -LO &quot;https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl&quot;</code></li>
<li>On a server node run:
<ul>
<li><code>sudo nano /etc/rancher/k3s/k3s.yaml</code></li>
</ul>
</li>
<li>Copy contents of that file to a file on your dev machine at location /home/user/.kube/config
<ul>
<li><em>Change IP address in config to match your Load Balancer</em></li>
</ul>
</li>
<li>verify it is working w/ <code>kubectl cluster-info</code></li>
</ul>
<p>You can now control your K3s cluster from another machine, outside of the cluster!</p>
<h1 id="5-setup-rancher-as-a-container-within-the-cluster">5. Setup Rancher as a container within the cluster</h1>
<p>Deploying Rancher on Workers using Helm <!-- raw HTML omitted -->
This deployment will be using the self-generated Rancher Certificate. <!-- raw HTML omitted -->
Either from a Master Node, or the Controller machine (If you followed step 4):</p>
<ol>
<li>
<p>Add the Helm Chart Repository</p>
<ul>
<li>Install helm
<ul>
<li><code>curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3</code></li>
<li><code>chmod 700 get_helm.sh</code></li>
<li><code>./get_helm.sh</code></li>
</ul>
</li>
<li>Use Stable release: <code>helm repo add rancher-stable https://releases.rancher.com/server-charts/stable</code></li>
</ul>
</li>
<li>
<p>Create Namespace within K3s for Rancher</p>
<ul>
<li><code>kubectl create namespace cattle-system</code></li>
</ul>
</li>
<li>
<p>Install Cert Manager (Required for self-hosted cert)</p>
<ul>
<li><code>kubectl apply -f https://github.com/jetstack/cert-manager/releases/download/v1.5.1/cert-manager.crds.yaml</code></li>
<li><code>helm repo add jetstack https://charts.jetstack.io</code></li>
<li><code>helm repo update</code></li>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span> helm install cert-manager jetstack/cert-manager <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --namespace cert-manager <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --create-namespace <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --version v1.5.1
</span></span></code></pre></div><em>If you experience an issue running this, such as localhost:8080 error, add KUBECONFIG as an environment variable to fix it:</em> <code>export KUBECONFIG=/etc/rancher/k3s/k3s.yaml</code>
<em>If that does not fix it, ensure the .kube config file exists in the proper locaiton</em> <code>kubectl config view --raw &gt; ~/.kube/config</code></li>
<li>Verify it is working w/ <code>kubectl get pods --namespace cert-manager</code></li>
</ul>
</li>
<li>
<p>Install Rancher using Helm</p>
<ul>
<li>
<pre tabindex="0"><code>  helm install rancher rancher-stable/rancher \
  --namespace cattle-system \
  --set hostname=port.lan \
  --set replicas=3 \
  --set bootstrapPassword=password
</code></pre></li>
<li>Check on deployment w/ <code>kubectl -n cattle-system rollout status deploy/rancher</code></li>
<li>Once finished, obtain info on deployment w/ <code>kubectl -n cattle-system get deploy rancher</code></li>
</ul>
</li>
<li>
<p>Once Rancher is deployed</p>
<ul>
<li>Navigate to {LoadBalancer-DNS} site
<ul>
<li><em>It must be the DNS entry of the Load Balancer due to the certification. An IP adddress will NOT work</em></li>
</ul>
</li>
<li>Find your secret using command given at site login, and log into the site</li>
</ul>
</li>
</ol>
<p>Bam, Rancher installed, and it is now highly available.</p>
<h2 id="troubeshooting-rancher">Troubeshooting Rancher</h2>
<ul>
<li>If you must uninstall and reinstall Rancher for any reason, I recommend these steps (They are painful)
<ul>
<li>For the name spaces affecting Rancher Directly,</li>
<li><code>sudo kubectl delete namespace namespace-name</code></li>
<li>Check it w/ <code>kubectl get ns</code></li>
<li>If stuck in terminating, <code>kubectl edit ns namespace-name</code>
<ul>
<li>Delete everything under the finalizer: fields (Sometimes there are two.)</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="useful-resources--commands">Useful Resources &amp; Commands</h1>
<h2 id="useful-docker-commands">Useful Docker Commands</h2>
<ul>
<li>The load balancer and database are setup using Docker-compose
<ul>
<li>Useful Docker compose commands:</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>	<span style="color:#75715e"># Sping up a docker based on docker-compose.yml file</span>
</span></span><span style="display:flex;"><span>	docker-compose up -f <span style="color:#e6db74">&#39;filenamehere&#39;</span>
</span></span><span style="display:flex;"><span>	<span style="color:#75715e"># Sping up a docker and keep it running</span>
</span></span><span style="display:flex;"><span>	docker-compose up -d
</span></span><span style="display:flex;"><span>	<span style="color:#75715e"># Find list of running docker processes</span>
</span></span><span style="display:flex;"><span>	docker ps
</span></span><span style="display:flex;"><span>	<span style="color:#75715e"># Get into shell of a running docker</span>
</span></span><span style="display:flex;"><span>	docker exec -it <span style="color:#f92672">[</span>option<span style="color:#f92672">]</span> bash
</span></span><span style="display:flex;"><span>	<span style="color:#75715e"># Update running docker with new configuration changes</span>
</span></span><span style="display:flex;"><span>	docker-compose up -d --force-recreate
</span></span></code></pre></div><pre tabindex="0"><code></code></pre></li>
</ul>
<h2 id="useful-kubectl-commands">Useful Kubectl Commands</h2>
<ul>
<li>Kubernetes commands (Mostly pulled from <a href="https://kubernetes.io/docs/reference/kubectl/cheatsheet/">kubectl cheat sheet</a>)
<ul>
<li>Finding ressources</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>Get commands with basic output
</span></span><span style="display:flex;"><span>bectl config view 						  <span style="color:#75715e"># Show Merged kubeconfig settings.</span>
</span></span><span style="display:flex;"><span>beclt get nodes							  <span style="color:#75715e"># Show all nodes in the cluster</span>
</span></span><span style="display:flex;"><span>bectl get services                          <span style="color:#75715e"># List all services in the namespace</span>
</span></span><span style="display:flex;"><span>bectl get pods --all-namespaces             <span style="color:#75715e"># List all pods in all namespaces</span>
</span></span><span style="display:flex;"><span>bectl get pods -o wide                      <span style="color:#75715e"># List all pods in the current namespace, with more details</span>
</span></span><span style="display:flex;"><span>bectl get deployment my-dep                 <span style="color:#75715e"># List a particular deployment</span>
</span></span><span style="display:flex;"><span>bectl get pods                              <span style="color:#75715e"># List all pods in the namespace</span>
</span></span><span style="display:flex;"><span>bectl get pod my-pod -o yaml                <span style="color:#75715e"># Get a pod&#39;s YAML```</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Describe commands with verbose output
</span></span><span style="display:flex;"><span>bectl describe nodes my-node
</span></span><span style="display:flex;"><span>bectl describe pods my-pod
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>List Services Sorted by Name
</span></span><span style="display:flex;"><span>bectl get services --sort-by<span style="color:#f92672">=</span>.metadata.name
</span></span></code></pre></div><pre tabindex="0"><code>Updating resources
`bash
bectl set image deployment/frontend www=image:v2               # Rolling update &#34;www&#34; containers of &#34;frontend&#34; deployment, 	updating the image
bectl rollout history deployment/frontend                      # Check the history of deployments including the revision 
bectl rollout undo deployment/frontend                         # Rollback to the previous deployment
bectl rollout undo deployment/frontend --to-revision=2         # Rollback to a specific revision
bectl rollout status -w deployment/frontend                    # Watch rolling update status of &#34;frontend&#34; deployment until 	completion
bectl rollout restart deployment/frontend                      # Rolling restart of the &#34;frontend&#34; deployment
</code></pre><pre tabindex="0"><code>Allow kubectl without sudo priviledge `sudo chmod 644 /etc/rancher/k3s/k3s.yaml`
</code></pre></li>
</ul>
<h2 id="resources">Resources</h2>
<ul>
<li>Shout out to <a href="https://github.com/TheQuib/k3s">TheQuib</a> I thank him for his collaboration on this</li>
<li>Rancher <a href="https://rancher.com/docs/k3s/latest/en/">Documentation</a></li>
<li>Docker Compose <a href="https://docs.docker.com/compose/">Documentation</a></li>
</ul>
]]></content></item><item><title>Terraform - vSphere-WinServ-Deployment</title><link>https://cinderblook.github.io/posts/1/01/terraform-vsphere-winserv-deployment/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cinderblook.github.io/posts/1/01/terraform-vsphere-winserv-deployment/</guid><description>Overview The goal of this project is to deploy a ready-to-go windows server environment. This includes a domain controller, a replica domain controller, a DHCP server, and a fileserver. Additionally setting up users, groups, and OUs for the respective users within the domain. To complete this project, 3 steps are taken.
Use Packer to spin up a sys prepped and fully updated windows server 2022 iso for the environemnt Use Terraform to deploy 4 virtual machines into a vSphere environment Use Ansible to configure these 4 virtual machines as desired 1.</description><content type="html"><![CDATA[<h1 id="overview">Overview</h1>
<p>The goal of this project is to deploy a ready-to-go windows server environment. This includes a domain controller, a replica domain controller, a DHCP server, and a fileserver. Additionally setting up users, groups, and OUs for the respective users within the domain. <!-- raw HTML omitted -->
To complete this project, 3 steps are taken.</p>
<ol>
<li>Use Packer to spin up a sys prepped and fully updated windows server 2022 iso for the environemnt</li>
<li>Use Terraform to deploy 4 virtual machines into a vSphere environment</li>
<li>Use Ansible to configure these 4 virtual machines as desired</li>
</ol>
<h2 id="1-packers-role">1. Packer&rsquo;s Role:</h2>
<p>Create a Windows Server 2022 .iso that is updated and has VMTools installed by default using <a href="https://www.packer.io/">Packer</a>. In this solution, it will be geared to usage with vSphere, a VMware product.</p>
<p><strong>First: Packer uses <code>autounattend.xml</code> and <code>sysprep-autounattend.xml</code> to automate Windows Settings</strong></p>
<ul>
<li>It pulls Windows Server 2022 Datacenter Eval Edition (Desktop Experience) from Microsoft&rsquo;s site</li>
<li>Installs &amp; configure OpenSSH Client &amp; Server for remote connection</li>
<li>Installs VMware tools from ISO provided from the build ESX server</li>
</ul>
<p><strong>Packer Provisioner Steps</strong></p>
<ul>
<li>Updating OS via Windows Update</li>
<li>Doing some OS adjustments
<ul>
<li>Set Windows telemetry settings to minimum</li>
<li>Show file extentions by default</li>
<li>Install <a href="https://chocolatey.org/">Chocolatey</a> - a Windows package manager
<ul>
<li>Install Microsoft Edge (Chromium)</li>
<li>Install Win32-OpenSSH-Server</li>
<li>Install PowerShell Core</li>
<li>Install 7-Zip</li>
<li>Install Notepad++</li>
</ul>
</li>
<li>Enable Powershell-Core (<code>pwsh</code>) to be the default SSHD shell</li>
</ul>
</li>
<li>Cleanup tasks</li>
<li>Remove CDROM drives from VM template (otherwise there would be 2)</li>
</ul>
<h2 id="2-terraforms-role">2. Terraform&rsquo;s Role:</h2>
<p>Main role: Deploy the Virtual Machines</p>
<ul>
<li>Setup the four Windows Servers (Primary Domain Controller, Replica Domain Controller, DHCP, Fileshare)
<ul>
<li>Using the vSphere provider:
<ul>
<li>Assign appropriate resources to each machine</li>
</ul>
</li>
</ul>
</li>
<li>Once prepared with appropriate values and the networking is in place:
<ul>
<li>Navigate to the Terraform directory and run these commands</li>
<li><code>terraform init</code> Pull proper Terraform providers and modules used</li>
<li><code>terraform validate</code> This will return whether the configuration is valid or not</li>
<li><code>terraform apply</code> &hellip; <code>yes</code> Actually apply the configuration</li>
</ul>
</li>
</ul>
<h2 id="terraform-variable-files">Terraform Variable files</h2>
<ul>
<li><em>variables.tf</em>
<ul>
<li>Declare variables that will be used with the Terraform configuration</li>
</ul>
</li>
<li><em>terraform.tfvars</em>
<ul>
<li>Assign variables that will be used with the Terraform configuration</li>
</ul>
</li>
</ul>
<h2 id="3-ansibles-role">3. Ansible&rsquo;s Role:</h2>
<p>Main role: Configure the deployed Virtual Machines.</p>
<ul>
<li>Setup Windows Server Feature: Domain
<ul>
<li>Primary Domain Controller</li>
<li>Replica Domain Controller</li>
<li>Auto-Join the Virutal Machines to the respective Domain created</li>
<li>Create a few users and groups within Active Directory</li>
</ul>
</li>
<li>Setup Windows Ssrver Feature: DHCP
<ul>
<li>Setup DHCP Scope</li>
<li>Authorize it to the Domain.</li>
</ul>
</li>
<li>Setup Windows Server Feature: File Sharing
<ul>
<li>Create two shares
<ul>
<li>An employee share and administrator share. These shares are assigned group permissions.</li>
</ul>
</li>
</ul>
</li>
<li>Common Configurations
<ul>
<li>Enable RDP and allow it through the firewall on all windows servers created</li>
</ul>
</li>
</ul>
<h2 id="ansible-variable-files">Ansible Variable files</h2>
<ul>
<li><em>inventory.yml</em>
<ul>
<li>Modify hosts associated with the playbook. Assign the IP addressing.</li>
</ul>
</li>
<li><em>winlab.yml</em>
<ul>
<li>Associate &lsquo;roles&rsquo; to the hosts identified in the inventory file.</li>
<li>These &lsquo;roles&rsquo; are folders within the directory containing a set of code to configure per host</li>
</ul>
</li>
<li><em>ansible.cfg</em>
<ul>
<li>Tells ansible variable information. In this scenario, identifies to use inventory.yml file.</li>
</ul>
</li>
<li><em>./group_vars/all.yml</em>
<ul>
<li>Contains specific variable information used within the ./roles/* Ansible code.</li>
</ul>
</li>
</ul>
<h1 id="prerequisites">Prerequisites</h1>
<ul>
<li>Linux machine with the following
<ul>
<li>Ansible
<ul>
<li><code>sudo apt update</code></li>
<li><code>sudo apt install software-properties-common</code></li>
<li><code>sudo add-apt-repository --yes --update ppa:ansible/ansible</code></li>
<li><code>sudo apt install ansible</code></li>
</ul>
</li>
<li>Terraform
<ul>
<li><code>sudo apt-get update &amp;&amp; sudo apt-get install -y gnupg software-properties-common curl</code></li>
<li><code>curl -fsSL https://apt.releases.hashicorp.com/gpg | sudo apt-key add -</code></li>
<li><code>sudo apt-add-repository &quot;deb [arch=amd64] https://apt.releases.hashicorp.com $(lsb_release -cs) main&quot;</code></li>
<li><code>sudo apt-get update &amp;&amp; sudo apt-get install terraform</code></li>
</ul>
</li>
<li>Packer
<ul>
<li><code>curl -fsSL https://apt.releases.hashicorp.com/gpg | sudo apt-key add -</code></li>
<li><code>sudo apt-add-repository &quot;deb [arch=amd64] https://apt.releases.hashicorp.com $(lsb_release -cs) main&quot;</code></li>
<li><code>sudo apt-get update &amp;&amp; sudo apt-get install packer</code></li>
</ul>
</li>
<li>Git
<ul>
<li><code>sudo apt-get install git</code></li>
</ul>
</li>
</ul>
</li>
<li>A Code Interprester
<ul>
<li>I recommend <a href="https://code.visualstudio.com/">Visual-Studio-Code</a></li>
</ul>
</li>
<li>vSphere Lab Environment
<ul>
<li><a href="https://www.vmware.com/products/vsphere.html">vSphere</a> &mdash; <em>Note: This project is using vSphere version 7.0.0</em>
<!-- raw HTML omitted --></li>
</ul>
</li>
</ul>
<h1 id="packer">Packer</h1>
<h2 id="navigate-to-packer-directory">Navigate to Packer Directory</h2>
<ul>
<li>First setup Packer environment
<ul>
<li><code>packer init -upgrade ws2022.pkr.hcl</code></li>
</ul>
</li>
<li>Then apply the Packer configuration to create the Windows Server 2022 Image
<ul>
<li><code>packer build -timestamp-ui -force -var-file=myvarfile.json ws2022.pkr.hcl</code></li>
</ul>
</li>
</ul>
<ul>
<li>This packer execute pulls the newest windows server datacenter 2022 eval .iso from microsoft populates it into the vSphere environment, in the specified datacenter/cluster/host/datastore</li>
<li>It then runs commands to: Grab DHCP, Updates the image, Enables SSH, Enables RDP, Configures necessary firewall settings, sets passwords/usernames, &amp; installs VMware Tools to base image</li>
<li>Additionally, it will install <a href="https://chocolatey.org/">Chocolatey</a> for packages, notepad++, Edge, &amp; 7-zip
<!-- raw HTML omitted --></li>
</ul>
<h2 id="after-packer-finishes">After Packer Finishes</h2>
<h6 id="roughly-an-hour-depending-on-processing-and-internet-speed"><em>Roughly an hour depending on processing and internet speed</em></h6>
<ul>
<li>Go into your vSphere and turn the resulting VM into a Template
<ul>
<li>Ensure this mimics the variables you have set in the terraform.tfvars file. This will be our next step.</li>
</ul>
</li>
</ul>
<h1 id="terraform">Terraform</h1>
<h2 id="navigate-to-terraform-directory">Navigate to Terraform Directory</h2>
<ul>
<li>Setup Terraform Environemnt
<ul>
<li><code>terraform init</code></li>
</ul>
</li>
<li>Format terraform to ensure it meets criteria required
<ul>
<li><code>terraform fmt</code></li>
</ul>
</li>
<li>Do a terraform plan to detect any potential errors in code and to see potential end result. Read over this
<ul>
<li><code>terraform plan</code></li>
</ul>
</li>
<li>Finally, if all the above appears correct, perform a terraform apply
<ul>
<li><code>terraform apply</code> &hellip; <code>yes</code>
<ul>
<li>This may take awhile, once it is done, double check in vSphere all necessary Virtual Machines were created properly <em>(For me this took 20 minutes to fully complete)</em></li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="ansible">Ansible</h1>
<h2 id="navigate-to-ansible-directory">Navigate to Ansible Directory</h2>
<ul>
<li>Once you have allowed Terraform to finish its configuraiton:
<ul>
<li>Navigate to your Ansible Directory, <code>cd &lt;path-to-Ansible&gt;</code></li>
<li>Run your ansible playbook <code>ansible-playbook winlab.yml</code>
<ul>
<li>This should run through and detail each change as it plays out</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="references-useduseful-links">References Used/Useful Links</h1>
<h3 id="i-sourced-various-code-and-peices-of-information-from-the-following-git-repositories">I sourced various code and peices of information from the following Git Repositories</h3>
<ul>
<li>Stefan Zimmermann <a href="https://gitlab.com/StefanZ8n/packer-ws2022">GitLab</a> <a href="https://z8n.eu/2021/11/09/building-a-windows-server-2022-ova-with-packer/">Article</a></li>
<li>Dmitry Teslya <a href="https://github.com/dteslya/win-iac-lab">GitHub</a></li>
</ul>
<h3 id="useful-places-for-refernece">Useful places for refernece</h3>
<ul>
<li>Tutorials for Terraform, Packer, and others <a href="https://learn.hashicorp.com/search?query=Packer">Hashicorp-Tutorials</a></li>
<li>Ansible <a href="https://docs.ansible.com/">Documentation</a>
<ul>
<li><a href="https://galaxy.ansible.com/ansible/windows?extIdCarryOver=true&amp;sc_cid=701f2000001OH7YAAW">Windows-Modules</a></li>
</ul>
</li>
<li>Terraform <a href="https://www.terraform.io/docs">Documentation</a></li>
<li>Packer <a href="https://www.packer.io/docs">Documentation</a></li>
</ul>
]]></content></item><item><title>Terraform - Azure-Serv-Deploy</title><link>https://cinderblook.github.io/posts/1/01/terraform-azure-serv-deploy/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cinderblook.github.io/posts/1/01/terraform-azure-serv-deploy/</guid><description>Overview Deploy and Configure 4 Windows 2022 Datacenter Servers in Azure.
Using Terraform in conjunction with Ansible: Create 4 Windows Servers Configure them to be a Primary Domain Controller, Replica Domain Controller, DHCP server, and Fileshare server Automate intial setup of the 4 servers to accept Ansible configuration from a Linux VM in Azure created VIA the Terraform deployment Terraform Main role: Deploy the Virtual Machines, setup Network environment, and provide intial parameters for both Windows and Linux environments running in the cloud</description><content type="html"><![CDATA[<h1 id="overview">Overview</h1>
<p>Deploy and Configure 4 Windows 2022 Datacenter Servers in Azure.</p>
<ul>
<li>Using Terraform in conjunction with Ansible: Create 4 Windows Servers
<ul>
<li>Configure them to be a Primary Domain Controller, Replica Domain Controller, DHCP server, and Fileshare server</li>
<li>Automate intial setup of the 4 servers to accept Ansible configuration from a Linux VM in Azure created VIA the Terraform deployment</li>
</ul>
</li>
</ul>
<h1 id="terraform">Terraform</h1>
<p>Main role: Deploy the Virtual Machines, setup Network environment, and provide intial parameters for both Windows and Linux environments running in the cloud</p>
<ul>
<li>Setup the four Windows Servers (Primary Domain Controller, Replica Domain Controller, DHCP, Fileshare) in Azure
<ul>
<li>These will all be Windows 2022 Datacenter Servers running on Standard_DS1_V2 by default</li>
</ul>
</li>
<li>Setup the one Linux server to deploy a pre-defined Ansible configuration across the Windows Environment for setting up Active Directory, DHCP, File shares, users, and groups.
<ul>
<li>This will all be an Ubuntu 18.04-LTS server running on Standard_B1s by default</li>
<li>It will use cloud-init to supply it the necessary setup at creation for Ansible and SSH connection VIA its public IP address.</li>
</ul>
</li>
<li>Supply necessary networking variables (Network interfaces, Security Groups, IP Addressing)</li>
<li>Supply necessary files for automation of Windows &amp; Linux environments (Cloud-Init &amp; Windows Unattend files)</li>
</ul>
<!-- raw HTML omitted -->
<h2 id="prerequisites">Prerequisites</h2>
<ul>
<li>Setup necessary Terraform <a href="https://learn.hashicorp.com/tutorials/terraform/install-cli">environment</a></li>
<li>Install and setup <a href="https://docs.microsoft.com/en-us/cli/azure/install-azure-cli">Azure CLI</a> or preferred method of authentication to Azure</li>
<li>Configure variables for desired outcomes (Outlined further down)
<!-- raw HTML omitted --></li>
</ul>
<h2 id="terraform-process">Terraform process</h2>
<ul>
<li>Using the Azure provider:
<ul>
<li>Login to Azure with <code>az connect</code></li>
</ul>
</li>
<li>Once prepared with appropriate values and the networking is in place:
<ul>
<li>Navigate to the Terraform directory and run these commands</li>
<li><code>terraform init</code> Pull proper Terraform providers and modules used</li>
<li><code>terraform validate</code> This will return whether the configuration is valid or not</li>
<li><code>terraform apply</code> &hellip; <code>yes</code> Actually apply the configuration</li>
</ul>
</li>
</ul>
<h2 id="terraform-file-structure">Terraform File Structure</h2>
<h3 id="providertf-file"><em>provider.tf</em> File</h3>
<ul>
<li>Calls necessary providers and sets their versions to be used in the Terraform configuration/deployment</li>
</ul>
<h3 id="networkingtf-file"><em>networking.tf</em> File</h3>
<ul>
<li>Defines resources, security groups, security rules, network interfaces, subnets, and public IPs to be created in Azure.
<ul>
<li>These variables are pulled from the VM creation resources</li>
<li>Managed with variables contained in terraform.tfvars file</li>
</ul>
</li>
</ul>
<h3 id="variablestf-terraformtfvars-files"><em>variables.tf, terraform.tfvars</em> Files</h3>
<ul>
<li>Alter variables within these files to ensure they meet your environment needs
<ul>
<li><em>variables.tf</em>
<ul>
<li>Declare variables that will be used with the Terraform configuration (Delcared intially or explicitely here as <code>locals</code> variables)
<ul>
<li><em>firsT_logon_commands</em> local variable points to a .xml file to configure first time logon in Windows. This enables each server to recieve Winrm data on port 5985 for Ansible configuration</li>
<li>*auto_logon_ runs a .xml configuration to log in once right after intial creation of VM. This allows <em>first_logon_commands</em> to execute automatically</li>
</ul>
</li>
</ul>
</li>
<li><em>terraform.tfvars</em>
<ul>
<li>Assign variables values here. These will be used with the Terraform configuration. If left blank, you can assign the variable at the terminal level when running the <code>terraform apply</code>
<ul>
<li>Alter Network values to desired IP addressing scheme
<ul>
<li><strong>Ensure IP addressing matches that in the Ansible configuration inventory.yml</strong></li>
</ul>
</li>
<li>Here you can alter azure values for <em>publisher</em>, <em>offer</em>, <em>sku</em>, <em>size</em>, <em>sa</em>, and <em>license</em> information for the Windows/Linux VMs</li>
<li>Additionally, ensure <code>linux_ssh_key</code> point to your public Key <code>id_rsa.pubc</code> file</li>
<li>I recommend to change <em>winadmin_username</em> &amp; <em>winadmin_password</em> variables to sensetive and blank so you can delcare them in preferrably Vaulty or via the CLI
<ul>
<li><strong><em>winadmin_username</em> &amp; <em>winadmin_password</em> MUST MATCH WHAT IS IN ANSIBLE /group_vars/all.yml</strong></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="01-linuxclienttf--02-winserverstf-files"><em>01-LinuxClient.tf</em> &amp; <em>02-WinServers.tf</em> Files</h3>
<ul>
<li>Here the creation of the VMs occur. Resources pull data from <em>networking.tf</em>, <em>variables.tf</em>, <em>terraform.tfvars</em> files.
<ul>
<li>Windows VMs are assigned unattend configurations for first time setup (/winfiles/FirstLogonCommands.xml &amp;&amp; <em>auto_logon</em> variable data)</li>
<li>Linux Machine is assigned a cloud-init file configuraiton for first time setup (/cloudinit/custom.yml)</li>
</ul>
</li>
</ul>
<h3 id="outputstf-file"><em>outputs.tf</em> File</h3>
<ul>
<li>Provides necessary ip information that is allocated to the VMs created.</li>
<li>This information by default includes:
<ul>
<li>Private IPs for all 5 deployed VMs (Which we know will by based on variables.tf file data)</li>
<li>Public IP for Linux machine (Not known by default, will be used for SSH connection if needed).</li>
</ul>
</li>
</ul>
<h2 id="useful-azure-related-functions">Useful Azure related functions</h2>
<p>Finding variable information for VM Images variables:</p>
<ul>
<li>You can use this command in Azure CLI to find UbuntuServer data. Change the values in offer, publisher, location, and sku for various other images.</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Powershell" data-lang="Powershell"><span style="display:flex;"><span>   az vm image list \
</span></span><span style="display:flex;"><span>   --location westus \
</span></span><span style="display:flex;"><span>   --publisher Canonical \  
</span></span><span style="display:flex;"><span>   --offer UbuntuServer \    
</span></span><span style="display:flex;"><span>   --sku 18.04-LTS \
</span></span><span style="display:flex;"><span>   --all --output table
</span></span></code></pre></div><ul>
<li>&ldquo;Check out Microsoft&rsquo;s&rdquo; <a href="https://docs.microsoft.com/en-us/azure/virtual-machines/linux/cli-ps-findimage">documentation</a> on finding VM information</li>
</ul>
<h1 id="ansible">Ansible</h1>
<p>Main role: Configure the deployed Virtual Machines.</p>
<ul>
<li>Setup Windows Server Feature: Domain
<ul>
<li>Primary Domain Controller</li>
<li>Replica Domain Controller</li>
<li>Auto-Join the Virutal Machines to the respective Domain created</li>
<li>Create a few users and groups within Active Directory</li>
</ul>
</li>
<li>Setup Windows Ssrver Feature: DHCP
<ul>
<li>Setup DHCP Scope</li>
<li>Authorize it to the Domain.</li>
</ul>
</li>
<li>Setup Windows Server Feature: File Sharing
<ul>
<li>Create two shares
<ul>
<li>An employee share and administrator share. These shares are assigned group permissions.</li>
</ul>
</li>
</ul>
</li>
<li>Common Configurations
<ul>
<li>Enable RDP and allow it through the firewall on all windows servers created at server level</li>
</ul>
</li>
</ul>
<h2 id="ansible-variable-files">Ansible Variable files</h2>
<ul>
<li><em>inventory.yml</em>
<ul>
<li>Modify hosts associated with the playbook. Assign the IP addressing
<ul>
<li><strong>MUST MATCH <em>terraform.tfvars</em> VARIABLE IP ADDRESSING</strong></li>
</ul>
</li>
</ul>
</li>
<li><em>winlab.yml</em>
<ul>
<li>Associate &lsquo;roles&rsquo; to the hosts identified in the inventory file.</li>
<li>These &lsquo;roles&rsquo; are folders within the directory containing a set of code to configure per host</li>
</ul>
</li>
<li><em>ansible.cfg</em>
<ul>
<li>Tells ansible variable information. In this scenario, identifies to use inventory.yml file.</li>
</ul>
</li>
<li><em>./group_vars/all.yml</em>
<ul>
<li>Contains specific variable information used within the ./roles/* Ansible code.</li>
<li>Alter user, password, port, connection, and cert variable information</li>
<li>Alter domain variables as well</li>
</ul>
</li>
</ul>
<h2 id="running-ansible">Running Ansible</h2>
<p>This is taken care of with terraform cloud-init file along with the file provisioner. The alternative would be below.</p>
<ul>
<li>On Linux Machine,
<ul>
<li>Requires: Python-pip, ansible-galaxzy-azure.azure_preview_modules</li>
<li>To Run: Navigate to Ansible directory and type <code>ansible-playbook winlab.yml</code></li>
</ul>
</li>
</ul>
<h1 id="useful-resources">Useful Resources</h1>
<h2 id="terraform-resources">Terraform Resources</h2>
<ul>
<li>Terraform <a href="https://www.terraform.io/docs">Documentation</a></li>
<li>Azure <a href="https://registry.terraform.io/providers/hashicorp/azurerm/2.96.0">Provider</a> &amp; <a href="https://registry.terraform.io/modules/Azure/compute/azurerm/latest">Modules</a></li>
<li>Cloud-init <a href="https://cloudinit.readthedocs.io/en/latest/">Documentation</a></li>
<li><a href="https://github.com/hashicorp/terraform-provider-azurerm">terraform-provider-azurerm</a> examples and documentation on GitHub</li>
</ul>
<h2 id="ansible-resources">Ansible Resources</h2>
<ul>
<li>Ansible <a href="https://docs.ansible.com/">Documentation</a>
<ul>
<li><a href="https://galaxy.ansible.com/ansible/windows?extIdCarryOver=true&amp;sc_cid=701f2000001OH7YAAW">Windows-Modules</a></li>
</ul>
</li>
</ul>
]]></content></item></channel></rss>